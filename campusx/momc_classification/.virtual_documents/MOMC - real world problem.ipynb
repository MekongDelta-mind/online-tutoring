























import pandas as pd
import numpy as np


df = pd.read_csv("./pet_train.csv")


new_col_order = ['PetID','Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID', 'VideoAmt', 'Description',  'PhotoAmt', 'Type','AdoptionSpeed']
df = df.reindex(columns=new_col_order)


df.head()


orig_df = df


df.dtypes





#Helper fundtion - finding unique values for the columns:
def unique_values(df):
  for col in df.columns:
    print(f"==================================Unique values for column ``` {col} ``` ")
    print(df[col].unique())
    print(f"==============================END==============================\n")


unique_values(df)


df.shape


df.describe()


df.info()


df.isnull().sum()


df['Type'].value_counts(normalize=True)*100


df['AdoptionSpeed'].value_counts(normalize=True)*100














df.columns


target_cols = ['Type', 'AdoptionSpeed']


selected_cols = [ col for col in df.columns if col not in target_cols]
selected_cols


# discarding Name and Description columns
selected_cols.remove('Name')
selected_cols.remove('Description')
selected_cols.remove('PetID')
selected_cols.remove('RescuerID')


num_cols = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']
# num_cols = ['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'State',]
cat_cols = [col for col in selected_cols if col not in num_cols]
selected_cols,cat_cols,num_cols


df[selected_cols] = df[selected_cols].astype({"PhotoAmt": int})


df[selected_cols].info()





# split the data then we can apply the processing
X = df[selected_cols]
y_targets = df[target_cols]


X.columns, type(y_targets)


from sklearn.model_selection import train_test_split


X_train, X_val, y_train, y_val = train_test_split(X, y_targets, test_size=0.25, random_state=42)


type(X_train), type(X_val), type(y_train), type(y_val),


type(y_train['Type']), type(y_val['AdoptionSpeed'])


X_train.shape, X_val.shape, y_train.shape, y_val.shape





from sklearn.preprocessing import OneHotEncoder


ohe_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')


ohe_encoder.fit(X_train[cat_cols]) 


encoded_data = ohe_encoder.transform(X_train[cat_cols])


ohe_encoder.get_feature_names_out()


encoded_df = pd.DataFrame(encoded_data, columns=ohe_encoder.get_feature_names_out())


encoded_df


encoded_df.index = X_train.index


# Joining tables
X_train = pd.concat([X_train, encoded_df], axis=1)


# Dropping old categorical columns
X_train.drop(cat_cols, axis=1, inplace=True)


# CHecking result
X_train.head()





from sklearn.preprocessing import MinMaxScaler


X_train[num_cols].describe().loc[['min', 'max'], :]


scaler = MinMaxScaler()


scaler.fit(X_train[num_cols])


scaled_data = scaler.transform(X_train[num_cols])


scaled_data


type(scaled_data), scaled_data.shape


scaled_df =  pd.DataFrame(data=scaled_data,columns=num_cols)


scaled_df.describe().loc[['min', 'max'], :]


scaled_df[num_cols].isnull().sum()


X_train[num_cols] = scaler.transform(X_train[num_cols])
X_train[num_cols].describe().loc[['min', 'max'], :]


X_train.shape


X_train[num_cols].isnull().sum()





from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier


('Type' in X_train.columns),('AdoptionSpeed' in X_train.columns) 


X1 = X_train
y1 = y_train['Type']


type_model = LogisticRegression()





ovr_type = OneVsRestClassifier(type_model)


X1.isnull().sum()


ovr_type.fit(X1, y1)


# # predicting on the same training Data and using it in the next prediction
# y_train_type_pred = ovr_type.predict(X1)
# y_train_type_pred,type(y_train_type_pred)


# from sklearn.metrics import classification_report


# target_names = ['Dog', 'Cat']


# # classification_report
# print(classification_report(y1, y_train_type_pred, target_names=target_names))





X2 =  pd.concat([X1, y_train['Type']], axis=1)
y2 = y_train['AdoptionSpeed']


X2.shape, y1.shape


adoptionSpeed_model = LogisticRegression(max_iter=1000)


ovr_adoption = OneVsRestClassifier(adoptionSpeed_model)


ovr_adoption.fit(X2,y2)








val_encoded_data = ohe_encoder.transform(X_val[cat_cols])


val_encoded_df = pd.DataFrame(val_encoded_data, columns=ohe_encoder.get_feature_names_out())


val_encoded_df.index = X_val.index


# Joining tables
X_val = pd.concat([X_val, val_encoded_df], axis=1)


# Dropping old categorical columns
X_val.drop(cat_cols, axis=1, inplace=True)


X_val.shape





X_val[num_cols] = scaler.transform(X_val[num_cols])


X_val[num_cols].describe().loc[['min', 'max'], :]





y_val_type_predict = ovr_type.predict(X_val)


y_val_type_predict,type(y_val_type_predict)


y_val_type_true = y_val['Type']


from sklearn.metrics import classification_report


target_names = ['Dog', 'Cat']


# classification_report
print(classification_report(y_val_type_true, y_val_type_predict, target_names=target_names))





y_val_type_predict.shape


y_val_type_predict_series = pd.Series(y_val_type_predict, name='Type')


X_val.index


y_val_type_predict_series.index = X_val.index


y_val_type_predict_series.index


X_val_adoption = pd.concat([X_val,y_val_type_predict_series ], axis=1)


X_val_adoption.isnull().sum()


X_val.shape, y_val_type_predict_series.shape, X_val_adoption.shape, y_val['AdoptionSpeed'].shape


y_val_adpotion_predict = ovr_adoption.predict(X_val_adoption)


y_val_adpotion_predict,type(y_val_adpotion_predict), np.unique(y_val_adpotion_predict)


y_val_adpotion_true = y_val['AdoptionSpeed']


# to be done once the classification_report is created
n_labels = [0,1,2,3,4]
target_names = []


# classification_report
print(classification_report(y_val_adpotion_true, y_val_adpotion_predict))
















































