























import pandas as pd
import numpy as np


df = pd.read_csv("./pet_train.csv")


new_col_order = ['PetID','Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID', 'VideoAmt', 'Description',  'PhotoAmt', 'Type','AdoptionSpeed']
df = df.reindex(columns=new_col_order)


df.head()


orig_df = df


df.dtypes


#Helper fundtion - finding unique values for the columns:
def unique_values(df):
  for col in df.columns:
    print(f"==================================Unique values for column ``` {col} ``` ")
    print(df[col].unique())
    print(f"==============================END==============================\n")


unique_values(df)


df.shape


df.describe()


df.info()


df.isnull().sum()


df['Type'].value_counts(normalize=True)*100


df['AdoptionSpeed'].value_counts(normalize=True)*100











df.columns


target_cols = ['Type', 'AdoptionSpeed']


selected_cols = [ col for col in df.columns if col not in target_cols]
selected_cols


# discarding Name and Description columns
selected_cols.remove('Name')
selected_cols.remove('Description')
selected_cols.remove('PetID')
selected_cols.remove('RescuerID')


num_cols = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']
# num_cols = ['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'State',]
cat_cols = [col for col in selected_cols if col not in num_cols]
selected_cols,cat_cols,num_cols


df[selected_cols] = df[selected_cols].astype({"PhotoAmt": int})


df[selected_cols].info()





# split the data then we can apply the processing
X = df[selected_cols]
y_targets = df[target_cols]


X.columns, type(y_targets)


from sklearn.model_selection import train_test_split


X_train, X_val, y_train, y_val = train_test_split(X, y_targets, test_size=0.25, random_state=42)


type(X_train), type(X_val), type(y_train), type(y_val),


type(y_train['Type']), type(y_val['AdoptionSpeed'])


X_train.shape, X_val.shape, y_train.shape, y_val.shape





from sklearn.preprocessing import OneHotEncoder


ohe_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')


ohe_encoder.fit(X_train[cat_cols]) 


encoded_data = ohe_encoder.transform(X_train[cat_cols])


ohe_encoder.get_feature_names_out()


encoded_df = pd.DataFrame(encoded_data, columns=ohe_encoder.get_feature_names_out())


encoded_df


encoded_df.index = X_train.index


# Joining tables
X_train = pd.concat([X_train, encoded_df], axis=1)


# Dropping old categorical columns
X_train.drop(cat_cols, axis=1, inplace=True)


# CHecking result
X_train.head()





from sklearn.preprocessing import MinMaxScaler


X_train[num_cols].describe().loc[['min', 'max'], :]


scaler = MinMaxScaler()


scaler.fit(X_train[num_cols])


scaled_data = scaler.transform(X_train[num_cols])


scaled_data


type(scaled_data), scaled_data.shape


scaled_df =  pd.DataFrame(data=scaled_data,columns=num_cols)


scaled_df.describe().loc[['min', 'max'], :]


X_train[num_cols] = scaled_df[num_cols]


X_train[num_cols].describe().loc[['min', 'max'], :]











from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.multioutput import MultiOutputClassifier

# Separate features and targets
X = df.drop(['Type', 'AdoptionSpeed'], axis=1)
y_type = df['Type']
y_speed = df['AdoptionSpeed']

# Split data into train and test sets
X_train, X_test, y_train_type, y_test_type = train_test_split(
    X, y_type, test_size=0.2, random_state=42)

# Define preprocessing for numerical and categorical data
numeric_features = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']
categorical_features = ['Name', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',
                        'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',
                        'Sterilized', 'Health', 'State', 'RescuerID', 'Description']

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

# Define classifiers for type and speed prediction
classifier_type = LogisticRegression()
classifier_speed = LogisticRegression()

# Bundle preprocessing and modeling code in a pipeline
pipeline_type = Pipeline(steps=[('preprocessor', preprocessor),
                                ('classifier', MultiOutputClassifier(classifier_type))]) # why multi output classifier is used?

# Fit the pipeline for type prediction
pipeline_type.fit(X_train, y_train_type)

# Use the predicted type as a feature for speed prediction
X_train_with_type = X_train.copy()
X_train_with_type['PredictedType'] = pipeline_type.predict(X_train)

# Split the augmented training data into train and test sets
X_train_augmented, X_test_augmented, y_train_speed, y_test_speed = train_test_split(
    X_train_with_type, y_speed, test_size=0.2, random_state=42)

# Fit the pipeline for speed prediction using augmented data
pipeline_speed = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', classifier_speed)])
pipeline_speed.fit(X_train_augmented, y_train_speed)

# Predictions
y_pred_speed = pipeline_speed.predict(X_test_augmented)































