























import pandas as pd
import numpy as np


df = pd.read_csv("./pet_train.csv")


new_col_order = ['PetID','Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID', 'VideoAmt', 'Description',  'PhotoAmt', 'Type','AdoptionSpeed']
df = df.reindex(columns=new_col_order)


df.head()


orig_df = df


df.dtypes


#Helper fundtion - finding unique values for the columns:
def unique_values(df):
  for col in df.columns:
    print(f"==================================Unique values for column ``` {col} ``` ")
    print(df[col].unique())
    print(f"==============================END==============================\n")


unique_values(df)











from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.multioutput import MultiOutputClassifier

# Separate features and targets
X = df.drop(['Type', 'AdoptionSpeed'], axis=1)
y_type = df['Type']
y_speed = df['AdoptionSpeed']

# Split data into train and test sets
X_train, X_test, y_train_type, y_test_type = train_test_split(
    X, y_type, test_size=0.2, random_state=42)

# Define preprocessing for numerical and categorical data
numeric_features = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']
categorical_features = ['Name', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',
                        'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',
                        'Sterilized', 'Health', 'State', 'RescuerID', 'Description']

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

# Define classifiers for type and speed prediction
classifier_type = LogisticRegression()
classifier_speed = LogisticRegression()

# Bundle preprocessing and modeling code in a pipeline
pipeline_type = Pipeline(steps=[('preprocessor', preprocessor),
                                ('classifier', MultiOutputClassifier(classifier_type))])

# Fit the pipeline for type prediction
pipeline_type.fit(X_train, y_train_type)

# Use the predicted type as a feature for speed prediction
X_train_with_type = X_train.copy()
X_train_with_type['PredictedType'] = pipeline_type.predict(X_train)

# Split the augmented training data into train and test sets
X_train_augmented, X_test_augmented, y_train_speed, y_test_speed = train_test_split(
    X_train_with_type, y_speed, test_size=0.2, random_state=42)

# Fit the pipeline for speed prediction using augmented data
pipeline_speed = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', classifier_speed)])
pipeline_speed.fit(X_train_augmented, y_train_speed)

# Predictions
y_pred_speed = pipeline_speed.predict(X_test_augmented)







